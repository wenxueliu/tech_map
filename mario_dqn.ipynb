{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOA5FwZPeDYZLTSWSx+JKlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wenxueliu/tech_map/blob/master/mario_dqn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安装 DI-engine"
      ],
      "metadata": {
        "id": "X2D_q8-x-P9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install git+https://github.com/opendilab/DI-engine.git@main#egg=DI-engine\n",
        "!pip install pyecharts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up9xSLBc-YUU",
        "outputId": "b06cb36b-c510-4862-ef29-a4b71b573253"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting DI-engine\n",
            "  Cloning https://github.com/opendilab/DI-engine.git (to revision main) to /tmp/pip-install-r9pismds/di-engine_ecbe94f97bd546cab85b982c96c421f8\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/opendilab/DI-engine.git /tmp/pip-install-r9pismds/di-engine_ecbe94f97bd546cab85b982c96c421f8\n",
            "  Resolved https://github.com/opendilab/DI-engine.git to commit d919fa5f5da1ceb3efb187dc1d1f28f0be5b616d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools<=66.1.1 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (66.1.1)\n",
            "Requirement already satisfied: yapf==0.29.0 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (0.29.0)\n",
            "Requirement already satisfied: gym==0.25.1 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (0.25.1)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (from DI-engine) (0.29.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (1.25.2)\n",
            "Requirement already satisfied: DI-treetensor>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (0.4.1)\n",
            "Requirement already satisfied: DI-toolkit>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (0.2.1)\n",
            "Requirement already satisfied: trueskill in /usr/local/lib/python3.10/dist-packages (from DI-engine) (0.4.5)\n",
            "Requirement already satisfied: tensorboardX>=2.2 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (2.6.2.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from DI-engine) (0.17.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from DI-engine) (3.7.1)\n",
            "Requirement already satisfied: easydict==1.9 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (1.9)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from DI-engine) (6.0.1)\n",
            "Requirement already satisfied: enum_tools in /usr/local/lib/python3.10/dist-packages (from DI-engine) (0.12.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from DI-engine) (2.2.1)\n",
            "Requirement already satisfied: hickle in /usr/local/lib/python3.10/dist-packages (from DI-engine) (5.0.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from DI-engine) (0.9.0)\n",
            "Requirement already satisfied: click>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (7.1.2)\n",
            "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (2.31.0)\n",
            "Requirement already satisfied: flask~=1.1.2 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (1.1.4)\n",
            "Requirement already satisfied: responses~=0.12.1 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (0.12.1)\n",
            "Requirement already satisfied: URLObject>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (2.4.3)\n",
            "Requirement already satisfied: MarkupSafe==2.0.1 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (2.0.1)\n",
            "Requirement already satisfied: pynng in /usr/local/lib/python3.10/dist-packages (from DI-engine) (0.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from DI-engine) (1.3.1)\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.10/dist-packages (from DI-engine) (5.0.5)\n",
            "Requirement already satisfied: mpire>=2.3.5 in /usr/local/lib/python3.10/dist-packages (from DI-engine) (2.10.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.25.1->DI-engine) (0.0.8)\n",
            "Requirement already satisfied: hbutils>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from DI-toolkit>=0.1.0->DI-engine) (0.9.3)\n",
            "Requirement already satisfied: rich>=12.2.0 in /usr/local/lib/python3.10/dist-packages (from DI-toolkit>=0.1.0->DI-engine) (13.7.1)\n",
            "Requirement already satisfied: yattag>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from DI-toolkit>=0.1.0->DI-engine) (1.15.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from DI-toolkit>=0.1.0->DI-engine) (2.0.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from DI-toolkit>=0.1.0->DI-engine) (2.15.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from DI-toolkit>=0.1.0->DI-engine) (4.66.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from DI-toolkit>=0.1.0->DI-engine) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from DI-toolkit>=0.1.0->DI-engine) (1.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from DI-toolkit>=0.1.0->DI-engine) (0.13.1)\n",
            "Requirement already satisfied: treevalue>=1.4.11 in /usr/local/lib/python3.10/dist-packages (from DI-treetensor>=0.4.0->DI-engine) (1.4.12)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from flask~=1.1.2->DI-engine) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.10/dist-packages (from flask~=1.1.2->DI-engine) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.10/dist-packages (from flask~=1.1.2->DI-engine) (1.1.0)\n",
            "Requirement already satisfied: pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from mpire>=2.3.5->DI-engine) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->DI-engine) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->DI-engine) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->DI-engine) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->DI-engine) (2024.6.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from responses~=0.12.1->DI-engine) (1.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.2->DI-engine) (24.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.2->DI-engine) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->DI-engine) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.1.0->DI-engine) (12.5.40)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium->DI-engine) (0.0.4)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from hickle->DI-engine) (3.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->DI-engine) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->DI-engine) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->DI-engine) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->DI-engine) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->DI-engine) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->DI-engine) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->DI-engine) (2.8.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from pynng->DI-engine) (1.16.0)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis->DI-engine) (4.0.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->DI-engine) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->DI-engine) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->DI-engine) (4.2.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->DI-engine) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->DI-engine) (2.5.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->DI-engine) (1.3.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->DI-engine) (4.0.11)\n",
            "Requirement already satisfied: pytimeparse>=1.1.8 in /usr/local/lib/python3.10/dist-packages (from hbutils>=0.9.1->DI-toolkit>=0.1.0->DI-engine) (1.1.8)\n",
            "Requirement already satisfied: bitmath>=1.3.3.1 in /usr/local/lib/python3.10/dist-packages (from hbutils>=0.9.1->DI-toolkit>=0.1.0->DI-engine) (1.3.3.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from hbutils>=0.9.1->DI-toolkit>=0.1.0->DI-engine) (4.0.0)\n",
            "Requirement already satisfied: deprecation>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from hbutils>=0.9.1->DI-toolkit>=0.1.0->DI-engine) (2.1.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.2.0->DI-toolkit>=0.1.0->DI-engine) (3.0.0)\n",
            "Requirement already satisfied: graphviz>=0.17 in /usr/local/lib/python3.10/dist-packages (from treevalue>=1.4.11->DI-treetensor>=0.4.0->DI-engine) (0.20.3)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from treevalue>=1.4.11->DI-treetensor>=0.4.0->DI-engine) (0.3.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->pynng->DI-engine) (2.22)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->DI-toolkit>=0.1.0->DI-engine) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->DI-toolkit>=0.1.0->DI-engine) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->DI-toolkit>=0.1.0->DI-engine) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->DI-toolkit>=0.1.0->DI-engine) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->DI-engine) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->DI-toolkit>=0.1.0->DI-engine) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->DI-toolkit>=0.1.0->DI-engine) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->DI-toolkit>=0.1.0->DI-engine) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->DI-toolkit>=0.1.0->DI-engine) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->DI-toolkit>=0.1.0->DI-engine) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->DI-toolkit>=0.1.0->DI-engine) (0.7.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->DI-engine) (5.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->DI-toolkit>=0.1.0->DI-engine) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->DI-toolkit>=0.1.0->DI-engine) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->DI-toolkit>=0.1.0->DI-engine) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->DI-toolkit>=0.1.0->DI-engine) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.2.0->DI-toolkit>=0.1.0->DI-engine) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->DI-toolkit>=0.1.0->DI-engine) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->DI-toolkit>=0.1.0->DI-engine) (3.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pyecharts\n",
            "  Using cached pyecharts-2.0.5-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyecharts) (2.11.3)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from pyecharts) (3.10.0)\n",
            "Collecting simplejson (from pyecharts)\n",
            "  Using cached simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyecharts) (2.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->pyecharts) (0.2.13)\n",
            "Using cached pyecharts-2.0.5-py3-none-any.whl (146 kB)\n",
            "Using cached simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "Installing collected packages: simplejson, pyecharts\n",
            "Successfully installed pyecharts-2.0.5 simplejson-3.19.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "验证安装"
      ],
      "metadata": {
        "id": "jzQKfSd6-Hy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ding\n",
        "print(ding.__version__)\n",
        "!ding -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7sLRy-R-_Ea",
        "outputId": "d3feaedf-05e6-40bf-9b14-e03968ecb871"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v0.5.1\n",
            "/usr/local/lib/python3.10/dist-packages/treevalue/tree/integration/torch.py:21: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  register_for_torch(TreeValue)\n",
            "/usr/local/lib/python3.10/dist-packages/treevalue/tree/integration/torch.py:22: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  register_for_torch(FastTreeValue)\n",
            "/usr/local/lib/python3.10/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "given by the platformdirs library.  To remove this warning and\n",
            "see the appropriate new directories, set the environment variable\n",
            "`JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "The use of platformdirs will be the default in `jupyter_core` v6\n",
            "  from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n",
            "DI-engine, version v0.5.1.\n",
            "Developed by OpenDILab Contributors, opendilab@pjlab.org.cn.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安装 mario 需要的依赖"
      ],
      "metadata": {
        "id": "qyj8YlXQBqaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pettingzoo"
      ],
      "metadata": {
        "id": "pqUtVLKhBp_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "训练代码"
      ],
      "metadata": {
        "id": "1GU9f9zu_iK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym_super_mario_bros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuofTJO2GM95",
        "outputId": "907e7c9e-4419-4205-e381-fa249af0ae0a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gym_super_mario_bros\n",
            "  Downloading gym_super_mario_bros-7.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nes-py>=8.1.4 (from gym_super_mario_bros)\n",
            "  Downloading nes_py-8.2.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.7/77.7 kB\u001b[0m \u001b[31m711.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym_super_mario_bros) (0.25.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym_super_mario_bros) (1.25.2)\n",
            "Collecting pyglet<=1.5.21,>=1.4.0 (from nes-py>=8.1.4->gym_super_mario_bros)\n",
            "  Downloading pyglet-1.5.21-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from nes-py>=8.1.4->gym_super_mario_bros) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym_super_mario_bros) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.17.2->nes-py>=8.1.4->gym_super_mario_bros) (0.0.8)\n",
            "Downloading gym_super_mario_bros-7.4.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyglet-1.5.21-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nes-py\n",
            "  Building wheel for nes-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nes-py: filename=nes_py-8.2.1-cp310-cp310-linux_x86_64.whl size=535717 sha256=d2e41a4da3140a4c3d80b512080662e7f86465edb928e3d39a5da171e4eaf125\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/a7/d5/9aa14b15df740a53d41f702e4c795731b6c4da7925deb8476c\n",
            "Successfully built nes-py\n",
            "Installing collected packages: pyglet, nes-py, gym_super_mario_bros\n",
            "Successfully installed gym_super_mario_bros-7.4.0 nes-py-8.2.1 pyglet-1.5.21\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "初始化配置"
      ],
      "metadata": {
        "id": "wS541OXwKivy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from easydict import EasyDict\n",
        "\n",
        "mario_dqn_config = dict(\n",
        "    exp_name='mario_dqn_seed0',\n",
        "    env=dict(\n",
        "        collector_env_num=8,\n",
        "        evaluator_env_num=8,\n",
        "        n_evaluator_episode=8,\n",
        "        stop_value=100000,\n",
        "        replay_path='mario_dqn_seed0/video',\n",
        "    ),\n",
        "    policy=dict(\n",
        "        cuda=True,\n",
        "        model=dict(\n",
        "            obs_shape=[4, 84, 84],\n",
        "            action_shape=2,\n",
        "            encoder_hidden_size_list=[128, 128, 256],\n",
        "            dueling=True,\n",
        "        ),\n",
        "        nstep=3,\n",
        "        discount_factor=0.99,\n",
        "        learn=dict(\n",
        "            update_per_collect=10,\n",
        "            batch_size=32,\n",
        "            learning_rate=0.0001,\n",
        "            target_update_freq=500,\n",
        "        ),\n",
        "        collect=dict(n_sample=96, ),\n",
        "        eval=dict(evaluator=dict(eval_freq=2000, )),\n",
        "        other=dict(\n",
        "            eps=dict(\n",
        "                type='exp',\n",
        "                start=1.,\n",
        "                end=0.05,\n",
        "                decay=250000,\n",
        "            ),\n",
        "            replay_buffer=dict(replay_buffer_size=100000, ),\n",
        "        ),\n",
        "    ),\n",
        ")\n",
        "mario_dqn_config = EasyDict(mario_dqn_config)\n",
        "main_config = mario_dqn_config\n",
        "mario_dqn_create_config = dict(\n",
        "    env_manager=dict(type='subprocess'),\n",
        "    policy=dict(type='dqn'),\n",
        ")\n",
        "mario_dqn_create_config = EasyDict(mario_dqn_create_config)\n",
        "create_config = mario_dqn_create_config"
      ],
      "metadata": {
        "id": "SFOkqCFsJT3q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "导入依赖"
      ],
      "metadata": {
        "id": "4dyJd9fHKmlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gym\n",
        "from tensorboardX import SummaryWriter\n",
        "from easydict import EasyDict\n",
        "\n",
        "from ding.config import compile_config\n",
        "from ding.worker import BaseLearner, SampleSerialCollector, InteractionSerialEvaluator, AdvancedReplayBuffer\n",
        "from ding.envs import SyncSubprocessEnvManager, DingEnvWrapper, BaseEnvManager\n",
        "from ding.envs.env_wrappers import MaxAndSkipWrapper, WarpFrameWrapper, ScaledFloatFrameWrapper, FrameStackWrapper, \\\n",
        "    EvalEpisodeReturnWrapper\n",
        "from ding.policy import DQNPolicy\n",
        "from ding.model import DQN\n",
        "from ding.utils import set_pkg_seed\n",
        "from ding.rl_utils import get_epsilon_greedy_fn\n",
        "import gym_super_mario_bros\n",
        "from nes_py.wrappers import JoypadSpace\n"
      ],
      "metadata": {
        "id": "CH5zjQC_JL_E"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wrapped_mario_env():\n",
        "    return DingEnvWrapper(\n",
        "        JoypadSpace(gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\"), [[\"right\"], [\"right\", \"A\"]]),\n",
        "        cfg={\n",
        "            'env_wrapper': [\n",
        "                lambda env: MaxAndSkipWrapper(env, skip=4),\n",
        "                lambda env: WarpFrameWrapper(env, size=84),\n",
        "                lambda env: ScaledFloatFrameWrapper(env),\n",
        "                lambda env: FrameStackWrapper(env, n_frames=4),\n",
        "                lambda env: EvalEpisodeReturnWrapper(env),\n",
        "            ]\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "def main(cfg, seed=0):\n",
        "    cfg = compile_config(\n",
        "        cfg,\n",
        "        SyncSubprocessEnvManager,\n",
        "        DQNPolicy,\n",
        "        BaseLearner,\n",
        "        SampleSerialCollector,\n",
        "        InteractionSerialEvaluator,\n",
        "        AdvancedReplayBuffer,\n",
        "        save_cfg=True\n",
        "    )\n",
        "    collector_env_num, evaluator_env_num = cfg.env.collector_env_num, cfg.env.evaluator_env_num\n",
        "    collector_env = SyncSubprocessEnvManager(\n",
        "        env_fn=[wrapped_mario_env for _ in range(collector_env_num)], cfg=cfg.env.manager\n",
        "    )\n",
        "    evaluator_env = SyncSubprocessEnvManager(\n",
        "        env_fn=[wrapped_mario_env for _ in range(evaluator_env_num)], cfg=cfg.env.manager\n",
        "    )\n",
        "\n",
        "    # Set random seed for all package and instance\n",
        "    collector_env.seed(seed)\n",
        "    evaluator_env.seed(seed, dynamic_seed=False)\n",
        "    set_pkg_seed(seed, use_cuda=cfg.policy.cuda)\n",
        "\n",
        "    # Set up RL Policy\n",
        "    model = DQN(**cfg.policy.model)\n",
        "    policy = DQNPolicy(cfg.policy, model=model)\n",
        "\n",
        "    # Set up collection, training and evaluation utilities\n",
        "    tb_logger = SummaryWriter(os.path.join('./{}/log/'.format(cfg.exp_name), 'serial'))\n",
        "    learner = BaseLearner(cfg.policy.learn.learner, policy.learn_mode, tb_logger, exp_name=cfg.exp_name)\n",
        "    collector = SampleSerialCollector(\n",
        "        cfg.policy.collect.collector, collector_env, policy.collect_mode, tb_logger, exp_name=cfg.exp_name\n",
        "    )\n",
        "    evaluator = InteractionSerialEvaluator(\n",
        "        cfg.policy.eval.evaluator, evaluator_env, policy.eval_mode, tb_logger, exp_name=cfg.exp_name\n",
        "    )\n",
        "    replay_buffer = AdvancedReplayBuffer(cfg.policy.other.replay_buffer, tb_logger, exp_name=cfg.exp_name)\n",
        "\n",
        "    # Set up other modules, etc. epsilon greedy\n",
        "    eps_cfg = cfg.policy.other.eps\n",
        "    epsilon_greedy = get_epsilon_greedy_fn(eps_cfg.start, eps_cfg.end, eps_cfg.decay, eps_cfg.type)\n",
        "\n",
        "    # Training & Evaluation loop\n",
        "    while True:\n",
        "        # Evaluating at the beginning and with specific frequency\n",
        "        if evaluator.should_eval(learner.train_iter):\n",
        "            stop, reward = evaluator.eval(learner.save_checkpoint, learner.train_iter, collector.envstep)\n",
        "            if stop:\n",
        "                break\n",
        "        # Update other modules\n",
        "        eps = epsilon_greedy(collector.envstep)\n",
        "        # Sampling data from environments\n",
        "        new_data = collector.collect(train_iter=learner.train_iter, policy_kwargs={'eps': eps})\n",
        "        replay_buffer.push(new_data, cur_collector_envstep=collector.envstep)\n",
        "        # Training\n",
        "        for i in range(cfg.policy.learn.update_per_collect):\n",
        "            train_data = replay_buffer.sample(learner.policy.get_attribute('batch_size'), learner.train_iter)\n",
        "            if train_data is None:\n",
        "                break\n",
        "            learner.train(train_data, collector.envstep)\n",
        "    # evaluate\n",
        "    evaluator_env = BaseEnvManager(env_fn=[wrapped_mario_env for _ in range(evaluator_env_num)], cfg=cfg.env.manager)\n",
        "    evaluator_env.enable_save_replay(cfg.env.replay_path)  # switch save replay interface\n",
        "    evaluator = InteractionSerialEvaluator(\n",
        "        cfg.policy.eval.evaluator, evaluator_env, policy.eval_mode, tb_logger, exp_name=cfg.exp_name\n",
        "    )\n",
        "    evaluator.eval(learner.save_checkpoint, learner.train_iter, collector.envstep)"
      ],
      "metadata": {
        "id": "m24FwJlPJoss"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main(mario_dqn_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBbwqoBqJrmU",
        "outputId": "ff4b4607-aa8b-4126-9636-1180724e2dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "INFO:learner_logger:[RANK0]: DI-engine DRL Policy\n",
            "DQN(\n",
            "  (encoder): ConvEncoder(\n",
            "    (act): ReLU()\n",
            "    (main): Sequential(\n",
            "      (0): Conv2d(4, 128, kernel_size=(8, 8), stride=(4, 4))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2))\n",
            "      (3): ReLU()\n",
            "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (5): ReLU()\n",
            "      (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (mid): Linear(in_features=12544, out_features=256, bias=True)\n",
            "  )\n",
            "  (head): DuelingHead(\n",
            "    (A): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Linear(in_features=256, out_features=2, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (V): Sequential(\n",
            "      (0): Sequential(\n",
            "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (1): ReLU()\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Linear(in_features=256, out_features=1, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "INFO:evaluator_logger:[EVALUATOR]env 0 finish episode, final reward: 231.0000, current episode: 1\n",
            "INFO:evaluator_logger:[EVALUATOR]env 1 finish episode, final reward: 231.0000, current episode: 2\n",
            "INFO:evaluator_logger:[EVALUATOR]env 2 finish episode, final reward: 231.0000, current episode: 3\n",
            "INFO:evaluator_logger:[EVALUATOR]env 3 finish episode, final reward: 231.0000, current episode: 4\n",
            "INFO:evaluator_logger:[EVALUATOR]env 4 finish episode, final reward: 231.0000, current episode: 5\n",
            "INFO:evaluator_logger:[EVALUATOR]env 5 finish episode, final reward: 231.0000, current episode: 6\n",
            "INFO:evaluator_logger:[EVALUATOR]env 6 finish episode, final reward: 231.0000, current episode: 7\n",
            "INFO:evaluator_logger:[EVALUATOR]env 7 finish episode, final reward: 231.0000, current episode: 8\n",
            "INFO:evaluator_logger:\n",
            "+-------+------------+---------------------+---------------+---------------+\n",
            "| Name  | train_iter | ckpt_name           | episode_count | envstep_count |\n",
            "+-------+------------+---------------------+---------------+---------------+\n",
            "| Value | 0.000000   | iteration_0.pth.tar | 8.000000      | 320.000000    |\n",
            "+-------+------------+---------------------+---------------+---------------+\n",
            "+-------+-------------------------+---------------+---------------------+----------------------+\n",
            "| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |\n",
            "+-------+-------------------------+---------------+---------------------+----------------------+\n",
            "| Value | 40.000000               | 11.808040     | 27.100180           | 0.677504             |\n",
            "+-------+-------------------------+---------------+---------------------+----------------------+\n",
            "+-------+-------------+------------+------------+------------+\n",
            "| Name  | reward_mean | reward_std | reward_max | reward_min |\n",
            "+-------+-------------+------------+------------+------------+\n",
            "| Value | 231.000000  | 0.000000   | 231.000000 | 231.000000 |\n",
            "+-------+-------------+------------+------------+------------+\n",
            "+-------+--------------------------------------------------------------------------+\n",
            "| Name  | eval_episode_return                                                      |\n",
            "+-------+--------------------------------------------------------------------------+\n",
            "| Value | [[231.0], [231.0], [231.0], [231.0], [231.0], [231.0], [231.0], [231.0]] |\n",
            "+-------+--------------------------------------------------------------------------+\n",
            "\n",
            "INFO:learner_logger:[RANK0]: learner save ckpt in ./mario_dqn_seed0_240611_163442/ckpt/ckpt_best.pth.tar\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  logger.deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(done, (bool, np.bool8)):\n",
            "INFO:buffer_logger:=== Sample data 0 Times ===\n",
            "INFO:buffer_logger:\n",
            "+-------+----------+----------+--------------+--------------+\n",
            "| Name  | use_avg  | use_max  | priority_avg | priority_max |\n",
            "+-------+----------+----------+--------------+--------------+\n",
            "| Value | 1.000000 | 1.000000 | 1.000000     | 1.000000     |\n",
            "+-------+----------+----------+--------------+--------------+\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "| Name  | priority_min | staleness_avg | staleness_max | beta     |\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "| Value | 1.000000     | 0.000000      | 0.000000      | 0.400006 |\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "\n",
            "\n",
            "INFO:learner_logger:[RANK0]: === Training Iteration 0 Result ===\n",
            "INFO:learner_logger:\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Name  | cur_lr_avg | total_loss_avg | q_value_avg | target_q_value_avg |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Value | 0.000100   | 228.960129     | 0.029419    | 0.029383           |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "\n",
            "\n",
            "INFO:learner_logger:[RANK0]: learner save ckpt in ./mario_dqn_seed0_240611_163442/ckpt/iteration_0.pth.tar\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 480.000000 | 1600.000000 | 0.000000 | 480.000000   |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:collector_logger:collect end:\n",
            "episode_count: 2\n",
            "envstep_count: 158\n",
            "train_sample_count: 158\n",
            "avg_envstep_per_episode: 79.0\n",
            "avg_sample_per_episode: 79.0\n",
            "avg_envstep_per_sec: 36.406787003227755\n",
            "avg_train_sample_per_sec: 36.406787003227755\n",
            "avg_episode_per_sec: 0.4608454051041488\n",
            "reward_mean: 410.0\n",
            "reward_std: 184.0\n",
            "reward_max: 594.0\n",
            "reward_min: 226.0\n",
            "total_envstep_count: 1118\n",
            "total_train_sample_count: 1070\n",
            "total_episode_count: 2\n",
            "INFO:learner_logger:[RANK0]: === Training Iteration 100 Result ===\n",
            "INFO:learner_logger:\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Name  | cur_lr_avg | total_loss_avg | q_value_avg | target_q_value_avg |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Value | 0.000100   | 64.477753      | 13.554906   | 0.029424           |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 672.000000 | 2208.000000 | 0.000000 | 1152.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 480.000000 | 1632.000000 | 0.000000 | 1632.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:collector_logger:collect end:\n",
            "episode_count: 4\n",
            "envstep_count: 568\n",
            "train_sample_count: 568\n",
            "avg_envstep_per_episode: 142.0\n",
            "avg_sample_per_episode: 142.0\n",
            "avg_envstep_per_sec: 37.16506215043626\n",
            "avg_train_sample_per_sec: 37.16506215043626\n",
            "avg_episode_per_sec: 0.26172578979180466\n",
            "reward_mean: 600.25\n",
            "reward_std: 221.29095458984375\n",
            "reward_max: 802.0\n",
            "reward_min: 231.0\n",
            "total_envstep_count: 2075\n",
            "total_train_sample_count: 2046\n",
            "total_episode_count: 6\n",
            "INFO:buffer_logger:=== Sample data 200 Times ===\n",
            "INFO:buffer_logger:\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "| Name  | use_avg  | use_max   | priority_avg | priority_max |\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "| Value | 4.270833 | 19.000000 | 1.000000     | 1.000000     |\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "| Name  | priority_min | staleness_avg | staleness_max | beta     |\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "| Value | 1.000000     | 106.093750    | 200.000000    | 0.401206 |\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "\n",
            "\n",
            "INFO:learner_logger:[RANK0]: === Training Iteration 200 Result ===\n",
            "INFO:learner_logger:\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Name  | cur_lr_avg | total_loss_avg | q_value_avg | target_q_value_avg |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Value | 0.000100   | 87.232031      | 10.636039   | 0.029544           |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 672.000000 | 2208.000000 | 0.000000 | 2304.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:collector_logger:collect end:\n",
            "episode_count: 5\n",
            "envstep_count: 1271\n",
            "train_sample_count: 1271\n",
            "avg_envstep_per_episode: 254.2\n",
            "avg_sample_per_episode: 254.2\n",
            "avg_envstep_per_sec: 38.36175071900236\n",
            "avg_train_sample_per_sec: 38.36175071900236\n",
            "avg_episode_per_sec: 0.15091168654210213\n",
            "reward_mean: 848.2000122070312\n",
            "reward_std: 129.14085388183594\n",
            "reward_max: 1010.0\n",
            "reward_min: 713.0\n",
            "total_envstep_count: 3063\n",
            "total_train_sample_count: 3029\n",
            "total_episode_count: 11\n",
            "INFO:learner_logger:[RANK0]: === Training Iteration 300 Result ===\n",
            "INFO:learner_logger:\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Name  | cur_lr_avg | total_loss_avg | q_value_avg | target_q_value_avg |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Value | 0.000100   | 86.276575      | 9.950955    | 0.029507           |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 672.000000 | 2176.000000 | 0.000000 | 2976.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 672.000000 | 2080.000000 | 0.000000 | 3648.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:collector_logger:collect end:\n",
            "episode_count: 4\n",
            "envstep_count: 561\n",
            "train_sample_count: 561\n",
            "avg_envstep_per_episode: 140.25\n",
            "avg_sample_per_episode: 140.25\n",
            "avg_envstep_per_sec: 40.33733955186675\n",
            "avg_train_sample_per_sec: 40.33733955186675\n",
            "avg_episode_per_sec: 0.28761026418443314\n",
            "reward_mean: 540.5\n",
            "reward_std: 184.80056762695312\n",
            "reward_max: 720.0\n",
            "reward_min: 231.0\n",
            "total_envstep_count: 4060\n",
            "total_train_sample_count: 4010\n",
            "total_episode_count: 15\n",
            "INFO:buffer_logger:=== Sample data 400 Times ===\n",
            "INFO:buffer_logger:\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "| Name  | use_avg  | use_max   | priority_avg | priority_max |\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "| Value | 4.453125 | 18.000000 | 1.000000     | 1.000000     |\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "| Name  | priority_min | staleness_avg | staleness_max | beta     |\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "| Value | 1.000000     | 205.260417    | 400.000000    | 0.402406 |\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "\n",
            "\n",
            "INFO:learner_logger:[RANK0]: === Training Iteration 400 Result ===\n",
            "INFO:learner_logger:\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Name  | cur_lr_avg | total_loss_avg | q_value_avg | target_q_value_avg |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Value | 0.000100   | 80.751018      | 9.384554    | 0.029466           |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 576.000000 | 1888.000000 | 0.000000 | 4224.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 576.000000 | 2208.000000 | 0.000000 | 4800.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:collector_logger:collect end:\n",
            "episode_count: 5\n",
            "envstep_count: 1006\n",
            "train_sample_count: 1006\n",
            "avg_envstep_per_episode: 201.2\n",
            "avg_sample_per_episode: 201.2\n",
            "avg_envstep_per_sec: 39.63022210893108\n",
            "avg_train_sample_per_sec: 39.63022210893108\n",
            "avg_episode_per_sec: 0.19696929477599942\n",
            "reward_mean: 547.2000122070312\n",
            "reward_std: 262.0918884277344\n",
            "reward_max: 794.0\n",
            "reward_min: 223.0\n",
            "total_envstep_count: 5031\n",
            "total_train_sample_count: 4992\n",
            "total_episode_count: 20\n",
            "INFO:learner_logger:[RANK0]: === Training Iteration 500 Result ===\n",
            "INFO:learner_logger:\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Name  | cur_lr_avg | total_loss_avg | q_value_avg | target_q_value_avg |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Value | 0.000100   | 71.895930      | 8.410408    | 0.948591           |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 672.000000 | 2080.000000 | 0.000000 | 5472.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:collector_logger:collect end:\n",
            "episode_count: 6\n",
            "envstep_count: 1515\n",
            "train_sample_count: 1515\n",
            "avg_envstep_per_episode: 252.5\n",
            "avg_sample_per_episode: 252.5\n",
            "avg_envstep_per_sec: 39.07797845739431\n",
            "avg_train_sample_per_sec: 39.07797845739431\n",
            "avg_episode_per_sec: 0.1547642711183933\n",
            "reward_mean: 705.0\n",
            "reward_std: 300.3725280761719\n",
            "reward_max: 1250.0\n",
            "reward_min: 231.0\n",
            "total_envstep_count: 6018\n",
            "total_train_sample_count: 5979\n",
            "total_episode_count: 26\n",
            "INFO:buffer_logger:=== Sample data 600 Times ===\n",
            "INFO:buffer_logger:\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "| Name  | use_avg  | use_max   | priority_avg | priority_max |\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "| Value | 4.276042 | 18.000000 | 1.000000     | 1.000000     |\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "| Name  | priority_min | staleness_avg | staleness_max | beta     |\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "| Value | 1.000000     | 304.791667    | 600.000000    | 0.403606 |\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "\n",
            "\n",
            "INFO:learner_logger:[RANK0]: === Training Iteration 600 Result ===\n",
            "INFO:learner_logger:\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Name  | cur_lr_avg | total_loss_avg | q_value_avg | target_q_value_avg |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Value | 0.000100   | 51.370122      | 16.898685   | 8.349284           |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 576.000000 | 2080.000000 | 0.000000 | 6048.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 672.000000 | 2208.000000 | 0.000000 | 6720.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:collector_logger:collect end:\n",
            "episode_count: 4\n",
            "envstep_count: 629\n",
            "train_sample_count: 629\n",
            "avg_envstep_per_episode: 157.25\n",
            "avg_sample_per_episode: 157.25\n",
            "avg_envstep_per_sec: 40.11587996306214\n",
            "avg_train_sample_per_sec: 40.11587996306214\n",
            "avg_episode_per_sec: 0.2551089345822712\n",
            "reward_mean: 727.5\n",
            "reward_std: 333.521728515625\n",
            "reward_max: 1045.0\n",
            "reward_min: 231.0\n",
            "total_envstep_count: 7014\n",
            "total_train_sample_count: 6968\n",
            "total_episode_count: 30\n",
            "INFO:learner_logger:[RANK0]: === Training Iteration 700 Result ===\n",
            "INFO:learner_logger:\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Name  | cur_lr_avg | total_loss_avg | q_value_avg | target_q_value_avg |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Value | 0.000100   | 49.142767      | 16.590532   | 8.404065           |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 672.000000 | 1984.000000 | 0.000000 | 7392.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:collector_logger:collect end:\n",
            "episode_count: 3\n",
            "envstep_count: 576\n",
            "train_sample_count: 576\n",
            "avg_envstep_per_episode: 192.0\n",
            "avg_sample_per_episode: 192.0\n",
            "avg_envstep_per_sec: 37.67131407088387\n",
            "avg_train_sample_per_sec: 37.67131407088387\n",
            "avg_episode_per_sec: 0.19620476078585347\n",
            "reward_mean: 699.3333129882812\n",
            "reward_std: 431.732421875\n",
            "reward_max: 1270.0\n",
            "reward_min: 226.0\n",
            "total_envstep_count: 7987\n",
            "total_train_sample_count: 7940\n",
            "total_episode_count: 33\n",
            "INFO:buffer_logger:=== Sample data 800 Times ===\n",
            "INFO:buffer_logger:\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "| Name  | use_avg  | use_max   | priority_avg | priority_max |\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "| Value | 4.598958 | 18.000000 | 1.000000     | 1.000000     |\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "| Name  | priority_min | staleness_avg | staleness_max | beta     |\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "| Value | 1.000000     | 405.625000    | 790.000000    | 0.404806 |\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "\n",
            "\n",
            "INFO:learner_logger:[RANK0]: === Training Iteration 800 Result ===\n",
            "INFO:learner_logger:\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Name  | cur_lr_avg | total_loss_avg | q_value_avg | target_q_value_avg |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Value | 0.000100   | 54.838655      | 17.422575   | 9.026824           |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 576.000000 | 2208.000000 | 0.000000 | 7968.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 672.000000 | 2240.000000 | 0.000000 | 8640.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:collector_logger:collect end:\n",
            "episode_count: 4\n",
            "envstep_count: 980\n",
            "train_sample_count: 980\n",
            "avg_envstep_per_episode: 245.0\n",
            "avg_sample_per_episode: 245.0\n",
            "avg_envstep_per_sec: 40.983242539979884\n",
            "avg_train_sample_per_sec: 40.983242539979884\n",
            "avg_episode_per_sec: 0.16727854097950973\n",
            "reward_mean: 710.25\n",
            "reward_std: 314.4689025878906\n",
            "reward_max: 995.0\n",
            "reward_min: 231.0\n",
            "total_envstep_count: 8952\n",
            "total_train_sample_count: 8920\n",
            "total_episode_count: 37\n",
            "INFO:learner_logger:[RANK0]: === Training Iteration 900 Result ===\n",
            "INFO:learner_logger:\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Name  | cur_lr_avg | total_loss_avg | q_value_avg | target_q_value_avg |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Value | 0.000100   | 40.881738      | 16.248798   | 8.192690           |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 768.000000 | 2304.000000 | 0.000000 | 9408.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:collector_logger:collect end:\n",
            "episode_count: 6\n",
            "envstep_count: 1635\n",
            "train_sample_count: 1635\n",
            "avg_envstep_per_episode: 272.5\n",
            "avg_sample_per_episode: 272.5\n",
            "avg_envstep_per_sec: 42.323074304646234\n",
            "avg_train_sample_per_sec: 42.323074304646234\n",
            "avg_episode_per_sec: 0.15531403414549078\n",
            "reward_mean: 759.5\n",
            "reward_std: 326.7831726074219\n",
            "reward_max: 1301.0\n",
            "reward_min: 231.0\n",
            "total_envstep_count: 9954\n",
            "total_train_sample_count: 9919\n",
            "total_episode_count: 43\n",
            "INFO:buffer_logger:=== Sample data 1000 Times ===\n",
            "INFO:buffer_logger:\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "| Name  | use_avg  | use_max   | priority_avg | priority_max |\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "| Value | 4.223958 | 20.000000 | 1.000000     | 1.000000     |\n",
            "+-------+----------+-----------+--------------+--------------+\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "| Name  | priority_min | staleness_avg | staleness_max | beta     |\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "| Value | 1.000000     | 504.583333    | 999.000000    | 0.406006 |\n",
            "+-------+--------------+---------------+---------------+----------+\n",
            "\n",
            "\n",
            "INFO:learner_logger:[RANK0]: === Training Iteration 1000 Result ===\n",
            "INFO:learner_logger:\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Name  | cur_lr_avg | total_loss_avg | q_value_avg | target_q_value_avg |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Value | 0.000100   | 53.810392      | 16.810983   | 9.204365           |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 480.000000 | 1856.000000 | 0.000000 | 9888.000000  |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 672.000000 | 2240.000000 | 0.000000 | 10560.000000 |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n",
            "INFO:collector_logger:collect end:\n",
            "episode_count: 3\n",
            "envstep_count: 261\n",
            "train_sample_count: 261\n",
            "avg_envstep_per_episode: 87.0\n",
            "avg_sample_per_episode: 87.0\n",
            "avg_envstep_per_sec: 37.541476190669684\n",
            "avg_train_sample_per_sec: 37.541476190669684\n",
            "avg_episode_per_sec: 0.43151122058241015\n",
            "reward_mean: 396.6666564941406\n",
            "reward_std: 234.2880401611328\n",
            "reward_max: 728.0\n",
            "reward_min: 231.0\n",
            "total_envstep_count: 10911\n",
            "total_train_sample_count: 10888\n",
            "total_episode_count: 46\n",
            "INFO:learner_logger:[RANK0]: === Training Iteration 1100 Result ===\n",
            "INFO:learner_logger:\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Name  | cur_lr_avg | total_loss_avg | q_value_avg | target_q_value_avg |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "| Value | 0.000100   | 93.448299      | 24.424342   | 17.146660          |\n",
            "+-------+------------+----------------+-------------+--------------------+\n",
            "\n",
            "\n",
            "INFO:buffer_logger:In the past 60.1 seconds, buffer statistics is as follows:\n",
            "INFO:buffer_logger:\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Name  | pushed_in  | sampled_out | removed  | current_have |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "| Value | 672.000000 | 2208.000000 | 0.000000 | 11232.000000 |\n",
            "+-------+------------+-------------+----------+--------------+\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}