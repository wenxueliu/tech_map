

分布式锁



## 目标

用分布式锁解决服务多实例部署，共享资源如何保证互斥





功能性需求

1、提供分布式的加锁和解锁功能

2、支持阻塞和非阻塞

3、支持公平和非公平

非功能性需求

1、互斥性

2、可重入性

3、高可用：锁超时

4、高性能



## 分布式锁

### 分布式锁的特点

分布式锁一般有如下的特点：

- 互斥性： 同一时刻只能有一个线程持有锁
- 可重入性： 同一节点上的同一个线程如果获取了锁之后能够再次获取锁
- 锁超时：和J.U.C中的锁一样支持锁超时，防止死锁
- 高性能和高可用： 加锁和解锁需要高效，同时也需要保证高可用，防止分布式锁失效
- 具备阻塞和非阻塞性：能够及时从阻塞状态中被唤醒

### 具体思路

1、数据库：排它锁、乐观锁

2、redis：redisson

3、zookeeper：Apache Curator

4、etcd



## 基于 Mysql数据库的分布式锁

### 悲观锁

#### 实现原理

```mysql
CREATE TABLE `resource_lock` (
  `id` int(4) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `resource_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的资源名',
  `owner` varchar(64) NOT NULL DEFAULT '' COMMENT '锁拥有者',
  `desc` varchar(1024) NOT NULL DEFAULT '备注信息',
  `update_time` timestamp NOT NULL DEFAULT '' COMMENT '保存数据时间，自动生成',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uidx_resource_name` (`resource_name `) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='锁定中的资源';
```



加锁

```mysql
select * from resource_lock where resource_name = name for update
如果为空
	insert into resource_lock(reosurce_name,owner,count) values (name, 'ip',0)
```



优点

简单易用，好理解，保障数据强一致性。

缺点

1）在 RR 事务级别，select 的 for update 操作是基于`间隙锁（gap lock）` 实现的，是一种悲观锁的实现方式，所以存在`阻塞问题`。

2）高并发情况下，大量请求进来，会导致大部分请求进行排队，影响数据库稳定性，也会`耗费`服务的CPU等`资源`。

当获得锁的客户端等待时间过长时，会提示：

```
[40001][1205] Lock wait timeout exceeded; try restarting transaction
```

高并发情况下，也会造成占用过多的应用线程，导致业务无法正常响应。

3）如果优先获得锁的线程因为某些原因，一直没有释放掉锁，可能会导致`死锁`的发生。

4）锁的长时间不释放，会一直占用数据库连接，可能会将`数据库连接池撑爆`，影响其他服务。

5）MySql数据库会做查询优化，即便使用了索引，优化时发现全表扫效率更高，则可能会将行锁升级为表锁，此时可能就更悲剧了。

6）不支持可重入特性，并且超时等待时间是全局的，不能随便改动。

### 乐观锁

```mysql
CREATE TABLE `resource` (
  `id` int(4) NOT NULL AUTO_INCREMENT COMMENT '主键',
  `resource_name` varchar(64) NOT NULL DEFAULT '' COMMENT '资源名',
  `share` varchar(64) NOT NULL DEFAULT '' COMMENT '状态',
    `version` int(4) NOT NULL DEFAULT '' COMMENT '版本号',
  `desc` varchar(1024) NOT NULL DEFAULT '备注信息',
  `update_time` timestamp NOT NULL DEFAULT '' COMMENT '保存数据时间，自动生成',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uidx_resource_name` (`resource_name `) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='资源';
```



```
select * from resource where resource_name = xxx
update resource set version= 'newVersion' ... where resource_name = xxx and version = 'oldVersion'
如果失败，重试
```



优点：简单易用，保障数据一致性。

缺点：

1）加行锁的性能上有一定的开销

2）高并发场景下，线程内的`自旋操作` 会耗费一定的CPU资源。

另外，比如在更新数据状态的一些场景下，不考虑幂等性的情况下，可以直接利用 `行锁` 来保证数据一致性，示例：`update table set state = 1 where id = xxx and state = 0;`

##  Redis 的分布式锁

### 实现原理

对于某个 key，

1、第一个访问者，发现 key不存在，获得锁，设置 key 的值为随机数，并且设置 key 的过期时间。

2、后续访问者，由于 key 已经存在，无法获取锁。

3、第一个访问者执行完之后，删除 key，其他访问者才能获得锁。



### 潜在的风险

1、超时

2、网络异常

3、节点宕机

### 实现要点

1、锁超时：key 要设置过期时间，并且避免大量超时同时出现，超时时间要用加一个随机数

2、key与expire要保持原子性：如果不保持原子性，异常，导致没有设置超时时间

3、key对应的值为随机数：如果A线程设置锁，由于超时，A线程占用的锁被释放，B线程拿到锁，在 B线程占用所期间，A线程恢复，如果不加判断就删除key就会删除B占用的锁导致异常。解决办法就是：1、设置 key对应的 value 为随机数；2、删除 key 的时候，检查 value 是否为之前的 value。

4、客户端超时时间要小于服务端超时时间

5、redLock：由于节点宕机，锁没有同步到新的master节点。

6、可重入：支持可重入是一个锁的标配，否则非常容易出现 bug。	

7、失效时间如何设置：任务还没执行完，但是超时时间到了如何处理？简单续约？



### 普通分布式锁



### RedLock锁







**问题1：节点崩溃重启**

节点崩溃重启，会出现多个客户端持有锁。

假设一共有5个Redis节点：A、B、 C、 D、 E。设想发生了如下的事件序列：

1）客户端C1成功对Redis集群中A、B、C三个节点加锁成功（但D和E没有锁住）。

2）节点C Duang的一下，崩溃重启了，但客户端C1在节点C加锁未持久化完，丢了。

3）节点C重启后，客户端C2成功对Redis集群中C、D、 E尝试加锁成功了。

这样，悲剧了吧！客户端C1和C2同时获得了同一把分布式锁。

为了应对节点重启引发的锁失效问题，Antirez提出了`延迟重启`的概念，即一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，等待的时间大于锁的有效时间。

采用这种方式，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。

这其实也是通过人为补偿措施，降低不一致发生的概率。

**问题2：时钟跳跃**

假设一共有5个Redis节点：A、B、 C、 D、 E。设想发生了如下的事件序列：

1）客户端C1成功对Redis集群中A、B、 C三个节点成功加锁。但因网络问题，与D和E通信失败。

2）节点C上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。

3）客户端C2对Redis集群中节点C、 D、 E成功加了同一把锁。

此时，又悲剧了吧！客户端C1和C2同时都持有着同一把分布式锁。

为了应对`时钟跳跃`引发的锁失效问题，Antirez提出了应该禁止人为修改系统时间，使用一个不会进行「跳跃式」调整系统时钟的ntpd程序。这也是通过人为补偿措施，降低不一致发生的概率。

但是...，RedLock算法并没有解决，操作共享资源超时，导致锁失效的问题。

存在这么大争议的算法实现，还是不推荐使用的。



### 基于 Zookeeper 的分布式锁



### 基于 etcd 的分布式锁







## 结论

1、如果项目比较简单，那么用数据库，需要知道，数据库的 tps 在千级别。

2、如果项目正好用了 redis，推荐用 redis 

3、如果项目中同时用了 redis，zk，根据需求决定使用



## 参考

https://www.jianshu.com/p/9f128325c407

https://github.com/pjmike/redis-distributed-lock

https://www.jianshu.com/p/7e47a4503b87

https://www.jianshu.com/p/f302aa345ca8

[https://blog.battcn.com/2018/06/13/springboot/v2-cache-redislock/#%E5%85%B7%E4%BD%93%E4%BB%A3%E7%A0%81](https://blog.battcn.com/2018/06/13/springboot/v2-cache-redislock/#具体代码)

## 附录

### 数据库锁



数据库表

```mysql
CREATE TABLE `INT_LOCK` (
  `LOCK_KEY` varchar(64) NOT NULL COMMENT '锁 Key',
  `REGION` varchar(64) NOT NULL COMMENT '区域',
  `CLIENT_ID` varchar(64) COMMENT '客户端 id',
  `CREATED_DATE` DATETIME(6) NOT NULL COMMENT '创建时间',
  PRIMARY KEY (`client_id`),
  constraint INT_LOCK_PK primary key (LOCK_KEY, REGION)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='锁';
```



LockRepository

```java
import java.io.Closeable;

public interface LockRepository extends Closeable {
    boolean isAcquired(String var1);

    void delete(String var1);

    boolean acquire(String var1);

    void close();
}
```

DefaultLockRepository

```java
import java.util.Date;
import java.util.UUID;
import javax.sql.DataSource;
import org.springframework.beans.factory.InitializingBean;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.dao.DuplicateKeyException;
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.stereotype.Repository;
import org.springframework.transaction.annotation.Isolation;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.util.Assert;

@Repository
@Transactional
public class DefaultLockRepository implements LockRepository, InitializingBean {
    public static final String DEFAULT_TABLE_PREFIX = "INT_";
    public static final int DEFAULT_TTL = 10000;
    private final String id;
    private final JdbcTemplate template;
    private int ttl;
    private String prefix;
    private String region;
    private String deleteQuery;
    private String deleteExpiredQuery;
    private String deleteAllQuery;
    private String updateQuery;
    private String insertQuery;
    private String countQuery;

    @Autowired
    public DefaultLockRepository(DataSource dataSource) {
        this(dataSource, UUID.randomUUID().toString());
    }

    public DefaultLockRepository(DataSource dataSource, String id) {
        this.ttl = 10000;
        this.prefix = "INT_";
        this.region = "DEFAULT";
        this.deleteQuery = "DELETE FROM %sLOCK WHERE REGION=? AND LOCK_KEY=? AND CLIENT_ID=?";
        this.deleteExpiredQuery = "DELETE FROM %sLOCK WHERE REGION=? AND LOCK_KEY=? AND CREATED_DATE<?";
        this.deleteAllQuery = "DELETE FROM %sLOCK WHERE REGION=? AND CLIENT_ID=?";
        this.updateQuery = "UPDATE %sLOCK SET CREATED_DATE=? WHERE REGION=? AND LOCK_KEY=? AND CLIENT_ID=?";
        this.insertQuery = "INSERT INTO %sLOCK (REGION, LOCK_KEY, CLIENT_ID, CREATED_DATE) VALUES (?, ?, ?, ?)";
        this.countQuery = "SELECT COUNT(REGION) FROM %sLOCK WHERE REGION=? AND LOCK_KEY=? AND CLIENT_ID=? AND CREATED_DATE>=?";
        Assert.hasText(id, "id must not be null nor empty");
        this.template = new JdbcTemplate(dataSource);
        this.id = id;
    }

    public void setRegion(String region) {
        Assert.hasText(region, "Region must not be null or empty.");
        this.region = region;
    }

    public void setPrefix(String prefix) {
        this.prefix = prefix;
    }

    public void setTimeToLive(int timeToLive) {
        this.ttl = timeToLive;
    }

    public void afterPropertiesSet() {
        this.deleteQuery = String.format(this.deleteQuery, this.prefix);
        this.deleteExpiredQuery = String.format(this.deleteExpiredQuery, this.prefix);
        this.deleteAllQuery = String.format(this.deleteAllQuery, this.prefix);
        this.updateQuery = String.format(this.updateQuery, this.prefix);
        this.insertQuery = String.format(this.insertQuery, this.prefix);
        this.countQuery = String.format(this.countQuery, this.prefix);
    }

    public void close() {
        this.template.update(this.deleteAllQuery, new Object[]{this.region, this.id});
    }

    public void delete(String lock) {
        this.template.update(this.deleteQuery, new Object[]{this.region, lock, this.id});
    }

    @Transactional(
        isolation = Isolation.SERIALIZABLE,
        timeout = 1
    )
    public boolean acquire(String lock) {
        this.deleteExpired(lock);
        if (this.template.update(this.updateQuery, new Object[]{new Date(), this.region, lock, this.id}) > 0) {
            return true;
        } else {
            try {
                return this.template.update(this.insertQuery, new Object[]{this.region, lock, this.id, new Date()}) > 0;
            } catch (DuplicateKeyException var3) {
                return false;
            }
        }
    }

    public boolean isAcquired(String lock) {
        this.deleteExpired(lock);
        return (Integer)this.template.queryForObject(this.countQuery, Integer.class, new Object[]{this.region, lock, this.id, new Date(System.currentTimeMillis() - (long)this.ttl)}) == 1;
    }

    private void deleteExpired(String lock) {
        this.template.update(this.deleteExpiredQuery, new Object[]{this.region, lock, new Date(System.currentTimeMillis() - (long)this.ttl)});
    }
}
```





### Redisson

#### 获取锁

```java
<T> RFuture<T> tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand<T> command) {
    internalLockLeaseTime = unit.toMillis(leaseTime);
    // 获取锁时向5个redis实例发送的命令
    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,
              // 首先分布式锁的KEY不能存在，如果确实不存在，那么执行hset命令（hset REDLOCK_KEY uuid+threadId 1），并通过pexpire设置失效时间（也是锁的租约时间）
              "if (redis.call('exists', KEYS[1]) == 0) then " +
                  "redis.call('hset', KEYS[1], ARGV[2], 1); " +
                  "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                  "return nil; " +
              "end; " +
              // 如果分布式锁的KEY已经存在，并且value也匹配，表示是当前线程持有的锁，那么重入次数加1，并且设置失效时间
              "if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then " +
                  "redis.call('hincrby', KEYS[1], ARGV[2], 1); " +
                  "redis.call('pexpire', KEYS[1], ARGV[1]); " +
                  "return nil; " +
              "end; " +
              // 获取分布式锁的KEY的失效时间毫秒数
              "return redis.call('pttl', KEYS[1]);",
              // 这三个参数分别对应KEYS[1]，ARGV[1]和ARGV[2]
                Collections.<Object>singletonList(getName()), internalLockLeaseTime, getLockName(threadId));
}
```



#### 删除锁

```java
protected RFuture<Boolean> unlockInnerAsync(long threadId) {
    // 向5个redis实例都执行如下命令
    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,
            // 如果分布式锁KEY不存在，那么向channel发布一条消息
            "if (redis.call('exists', KEYS[1]) == 0) then " +
                "redis.call('publish', KEYS[2], ARGV[1]); " +
                "return 1; " +
            "end;" +
            // 如果分布式锁存在，但是value不匹配，表示锁已经被占用，那么直接返回
            "if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then " +
                "return nil;" +
            "end; " +
            // 如果就是当前线程占有分布式锁，那么将重入次数减1
            "local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); " +
            // 重入次数减1后的值如果大于0，表示分布式锁有重入过，那么只设置失效时间，还不能删除
            "if (counter > 0) then " +
                "redis.call('pexpire', KEYS[1], ARGV[2]); " +
                "return 0; " +
            "else " +
                // 重入次数减1后的值如果为0，表示分布式锁只获取过1次，那么删除这个KEY，并发布解锁消息
                "redis.call('del', KEYS[1]); " +
                "redis.call('publish', KEYS[2], ARGV[1]); " +
                "return 1; "+
            "end; " +
            "return nil;",
            // 这5个参数分别对应KEYS[1]，KEYS[2]，ARGV[1]，ARGV[2]和ARGV[3]
            Arrays.<Object>asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));

}
```



分布式锁实现原理

```java
public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException {
    // 实现要点之允许加锁失败节点限制
    int failedLocksLimit = failedLocksLimit();
    List<RLock> acquiredLocks = new ArrayList<RLock>(locks.size());
    // 实现要点之遍历所有节点通过EVAL命令执行lua加锁
    for (ListIterator<RLock> iterator = locks.listIterator(); iterator.hasNext();) {
        RLock lock = iterator.next();
        boolean lockAcquired;
        try {
            // 对节点尝试加锁
            lockAcquired = lock.tryLock(awaitTime, newLeaseTime, TimeUnit.MILLISECONDS);
        } catch (RedisConnectionClosedException|RedisResponseTimeoutException e) {
            // 如果抛出这类异常，为了防止加锁成功，但是响应失败，需要解锁
            unlockInner(Arrays.asList(lock));
            lockAcquired = false;
        } catch (Exception e) {
            // 抛出异常表示获取锁失败
            lockAcquired = false;
        }
        
        if (lockAcquired) {
            // 成功获取锁集合
            acquiredLocks.add(lock);
        } else {
            // 如果达到了允许加锁失败节点限制，那么break，即此次Redlock加锁失败
            if (locks.size() - acquiredLocks.size() == failedLocksLimit()) {
                break;
            }               
        }
    }
    return true;
}
```

